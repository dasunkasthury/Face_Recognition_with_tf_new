# -*- coding: utf-8 -*-
"""FaceEmotionRecog_with_FER2013_AUG_Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16uHwCGxgA82998Ap7r7XT1iOOwfUuqoL
"""



import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Reshape, Dropout, BatchNormalization
from tensorflow.keras.preprocessing import image
import numpy as np
import json
import os
import albumentations as alb
import time
import cv2
from tensorflow.keras.applications import ResNet152V2, VGG16
import keras

from tensorflow.keras.callbacks import EarlyStopping
from keras.preprocessing.image import img_to_array

def load_image(x):
    byte_img = tf.io.read_file(x)
    img = tf.io.decode_jpeg(byte_img)
    return img

gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
  tf.config.experimental.set_memory_growth(gpu, True)

print("GPU count ---------------------------------->>> ", gpus)

data_gen = ImageDataGenerator(shear_range=0.2, zoom_range=0.2, rescale=1./255, validation_split=0.2)
path_to_data = 'data/FER2013/with_augmented/content/data/aug/train'

training_set = data_gen.flow_from_directory(path_to_data,(48,48),color_mode='grayscale', subset="training") # Found 1378032 images belonging to 7 classes.
testing_set = data_gen.flow_from_directory(path_to_data,(48,48),color_mode='grayscale', subset="validation") # Found 344508 images belonging to 7 classes.

#######################################         ----------------------- MODEL 5 ------------------------------------------


early = EarlyStopping(monitor='val_loss', patience=5)

face_recognition_model_5 = keras.Sequential()

face_recognition_model_5.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1), padding='same',kernel_regularizer='l2'))
face_recognition_model_5.add(Conv2D(64, (3, 3), activation='relu',kernel_regularizer='l2'))
face_recognition_model_5.add(BatchNormalization())
face_recognition_model_5.add(MaxPooling2D(pool_size=(2, 2))) #max pooling to decrease dimension
face_recognition_model_5.add(Dropout(0.25)) #test

face_recognition_model_5.add(Conv2D(128, (3, 3), activation='relu',kernel_regularizer='l2'))
face_recognition_model_5.add(BatchNormalization())
face_recognition_model_5.add(MaxPooling2D(pool_size=(2, 2))) #max pooling to decrease dimension
face_recognition_model_5.add(Conv2D(128, (3, 3), activation='relu',kernel_regularizer='l2'))
face_recognition_model_5.add(BatchNormalization())
face_recognition_model_5.add(Dropout(0.25))

face_recognition_model_5.add(Flatten())

face_recognition_model_5.add(Dense(1024, activation = 'relu',kernel_regularizer='l2'))
face_recognition_model_5.add(Dropout(0.5))
face_recognition_model_5.add(Dense(7, activation = 'softmax'))


# compile
face_recognition_model_5.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss=keras.losses.CategoricalCrossentropy(),metrics=['acc'])

early = EarlyStopping(monitor='val_loss',patience=10)

face_recognition_model_5.summary()

history_new = face_recognition_model_5.fit(
    training_set, 
    epochs=60, 
    validation_data=testing_set, 
    batch_size=64,
    steps_per_epoch=1500,
    validation_steps=375, # (steps_per_epoch/8)*2
    callbacks=[early]
    )

face_recognition_model_5.save('face_recognition_model_5_60E_64BS_1500SPE_375VS.h5')

def plot_accuracy(history):
    plt.plot(history.history["acc"], color='red')
    plt.plot(history.history["val_acc"], color='orange')

    plt.title("60E_64BS_1500SPE_375VS_Accuracy")

    plt.legend(["acc","val_acc"], bbox_to_anchor =(0.65, 1.00))
    plt.show()

def plot_loss(history):
    plt.plot(history.history["loss"], color='blue')
    # plt.plot(history.history["loss"],color='green')
    plt.plot(history.history["val_loss"],color='olive')
    # plt.plot(history.history["recall_1"],color='violet')
    # plt.plot(history.history["specificity_at_sensitivity_1"],color='purple')

    # plt.plot(history.history["val_accuracy"],color='cyan')
    # plt.plot(history.history["val_auc_1"],color='yellow')

    plt.title("60E_64BS_1500SPE_375VS_Loss")

    plt.legend(["loss", "val_loss" ], bbox_to_anchor =(0.65, 1.00))
    plt.show()

plot_accuracy(history_new)
plot_loss(history_new)